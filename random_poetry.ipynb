{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "stupid-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import cmudict\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "amended-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = gutenberg.words('melville-moby_dick.txt')[4712:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comfortable-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_dict = cmudict.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-pendant",
   "metadata": {},
   "source": [
    "# Cleaning up the text\n",
    "\n",
    "- Turn to lower case\n",
    "- remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "moral-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(words):\n",
    "    # remove punctuation\n",
    "    # third parameter of str.maketrans are chars that will be mapped to None\n",
    "    transtab = str.maketrans('', '', string.punctuation)\n",
    "    temp_words = [w.translate(transtab) for w in words]\n",
    "    temp_words = [w for w in temp_words if w != '']\n",
    "    \n",
    "    # turn to lower case\n",
    "    temp_words = [w.lower() for w in temp_words]\n",
    "    \n",
    "    return temp_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-diameter",
   "metadata": {},
   "source": [
    "# Creating the markov chain (forward and backward looking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "overall-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markov(words):\n",
    "    markov_forward = defaultdict(list)\n",
    "    for i, w in enumerate(words[:-1]):\n",
    "        markov_forward[w].append(words[i + 1])\n",
    "    \n",
    "    markov_backward = defaultdict(list)\n",
    "    for i, w in enumerate(words[1:]):\n",
    "        markov_backward[w].append(words[i - 1])\n",
    "        \n",
    "    return markov_forward, markov_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-vehicle",
   "metadata": {},
   "source": [
    "# Get the stressed vowels of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "national-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stress_pattern(word):\n",
    "    # look up the word in the cmudict\n",
    "    if word in cmu_dict:\n",
    "        # get the first pronounciation of the word\n",
    "        cmu_word = cmu_dict[word][0]\n",
    "        pattern = ''\n",
    "        for c in cmu_word:\n",
    "            if c[-1] in '012':\n",
    "                pattern += c[-1]\n",
    "    else:\n",
    "        # word was not found\n",
    "        pattern = None\n",
    "        \n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-decline",
   "metadata": {},
   "source": [
    "# Generate a line based on a start or end word and pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "meaning-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_match(word_pattern, line_pattern, reverse=False):\n",
    "    \"\"\"\n",
    "    Match a word pattern (if the vowels are stressed or not) to a target pattern for a line of poetry.\n",
    "    \n",
    "    Patterns are in the form of '[012]+', e.g. '0102'. \n",
    "    - '0': vowel is not stressed\n",
    "    - '1': vowel has primary stress\n",
    "    - '2': vowel has secondary stress. Vowels with 2 in either the word pattern or line pattern will match any\n",
    "           vowel in the other pattern, e.g. '012' matches both '010', '011' and '012'.\n",
    "    See http://en.wikipedia.org/wiki/Arpabet or https://www.nltk.org/book/ch02.html, chapter 4.2 A Pronouncing Dictionary,\n",
    "    based on the nltk.corpus.cmudict CMU Pronouncing Dictionary for US English.\n",
    "    \"\"\"\n",
    "    if reverse:\n",
    "        word_pattern = word_pattern[::-1]\n",
    "        line_pattern = line_pattern[::-1]\n",
    "    for w, l in zip(list(word_pattern), list(line_pattern)):\n",
    "        if (l == '2') or (w == '2') or (w == l):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "published-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poetry_line(seed, pattern, reverse=False):\n",
    "    # look up list of following words\n",
    "    f_words = markov_backward[seed] if reverse else markov_forward[seed]\n",
    "    \n",
    "    # order the markov words in random order\n",
    "    for fw in random.sample(f_words, len(f_words)):\n",
    "        # get the pattern of the word\n",
    "        next_word_pattern = get_stress_pattern(fw)\n",
    "        if next_word_pattern and pattern_match(next_word_pattern, pattern, reverse):\n",
    "            remaining_pattern = pattern[:-len(next_word_pattern)] if reverse else pattern[len(next_word_pattern):]\n",
    "            # if no more pattern to consume, return the word we found\n",
    "            if remaining_pattern == '':\n",
    "                return [fw, ]\n",
    "            else:\n",
    "                remaining_phrase = generate_poetry_line(fw, remaining_pattern, reverse)\n",
    "                if remaining_phrase:\n",
    "                    return remaining_phrase + [fw, ] if reverse else [fw, ] + remaining_phrase\n",
    "                \n",
    "    # we didn't find a chain that matches the pattern\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-denmark",
   "metadata": {},
   "source": [
    "# Generate words that rhyme\n",
    "\n",
    "- Go through each word, select the last vowel and any following consonants\n",
    "- Add to a rhyme dictionary\n",
    "\n",
    "Any words in the same rhyme class will also automatically have the same pattern!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_rhyme(word):\n",
    "    # look up the word in the cmudict\n",
    "    if word in cmu_dict:\n",
    "        # get the first pronounciation of the word\n",
    "        cmu_word = cmu_dict[word][0]\n",
    "        # find the last vowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rhyme_dict(words):\n",
    "    rhyme_dict = defaultdict(list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-martin",
   "metadata": {},
   "source": [
    "# Generate multiple lines based on line patterns and lines rhyming with each other\n",
    "\n",
    "- Pick a start word based on:\n",
    "    - the pattern to match (e.g. pick a word '010' if line pattern ends in '010'\n",
    "    - the number of rhymes required (e.g. if lines 1 and 3 need to rhyme, pick a class of words that rhyme with each other\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-librarian",
   "metadata": {},
   "source": [
    "# Test the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "conscious-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = cleanup_text(sample_text)\n",
    "markov_forward, markov_backward = get_markov(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "primary-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['IH1', 'SH', 'M', 'IY0', 'L'], ['IH1', 'SH', 'M', 'EY0', 'L']]\n",
      "10\n",
      "[['W', 'EY1', 'L'], ['HH', 'W', 'EY1', 'L']]\n",
      "1\n",
      "[['SH', 'IH1', 'P']]\n",
      "1\n",
      "[['K', 'AA2', 'N', 'D', 'IH0', 'S', 'EH1', 'N', 'D', 'IH0', 'NG']]\n",
      "2010\n"
     ]
    }
   ],
   "source": [
    "test_words = ['ishmael', 'whale', 'ship', 'condescending']\n",
    "for tw in test_words:\n",
    "    print(cmu_dict[tw])\n",
    "    print(get_stress_pattern(tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "approximate-recycling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yes', 'a', 'hater', 'some', 'the', 'hinted', 'at', 'the']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random.seed(2021)\n",
    "seed = random.choice(clean_text)\n",
    "generate_poetry_line(seed, '1010101010', reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
