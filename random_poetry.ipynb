{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "stupid-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import cmudict\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "amended-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = gutenberg.words('melville-moby_dick.txt')[4712:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "comfortable-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_dict = cmudict.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-pendant",
   "metadata": {},
   "source": [
    "# Cleaning up the text\n",
    "\n",
    "- Turn to lower case\n",
    "- remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "moral-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(words):\n",
    "    # remove punctuation\n",
    "    # third parameter of str.maketrans are chars that will be mapped to None\n",
    "    transtab = str.maketrans('', '', string.punctuation)\n",
    "    temp_words = [w.translate(transtab) for w in words]\n",
    "    temp_words = [w for w in temp_words if w != '']\n",
    "    \n",
    "    # turn to lower case\n",
    "    temp_words = [w.lower() for w in temp_words]\n",
    "    \n",
    "    return temp_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-diameter",
   "metadata": {},
   "source": [
    "# Creating the markov chain (forward and backward looking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "overall-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_markov(words):\n",
    "    markov_forward = defaultdict(list)\n",
    "    for i, w in enumerate(words[:-1]):\n",
    "        markov_forward[w].append(words[i + 1])\n",
    "    \n",
    "    markov_backward = defaultdict(list)\n",
    "    for i, w in enumerate(words[1:]):\n",
    "        markov_backward[w].append(words[i - 1])\n",
    "        \n",
    "    return markov_forward, markov_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-vehicle",
   "metadata": {},
   "source": [
    "# Get the stressed vowels of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "national-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stress_pattern(word):\n",
    "    # look up the word in the cmudict\n",
    "    if word in cmu_dict:\n",
    "        # get the first pronounciation of the word\n",
    "        cmu_word = cmu_dict[word][0]\n",
    "        pattern = ''\n",
    "        for c in cmu_word:\n",
    "            if c[-1] in '012':\n",
    "                pattern += c[-1]\n",
    "    else:\n",
    "        # word was not found\n",
    "        pattern = None\n",
    "        \n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-decline",
   "metadata": {},
   "source": [
    "# Generate a line based on a start or end word and pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "meaning-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_match(word_pattern, line_pattern, reverse=False):\n",
    "    \"\"\"\n",
    "    Match a word pattern (if the vowels are stressed or not) to a target pattern for a line of poetry.\n",
    "    \n",
    "    Patterns are in the form of '[012]+', e.g. '0102'. \n",
    "    - '0': vowel is not stressed\n",
    "    - '1': vowel has primary stress\n",
    "    - '2': vowel has secondary stress. Vowels with 2 in either the word pattern or line pattern will match any\n",
    "           vowel in the other pattern, e.g. '012' matches both '010', '011' and '012'.\n",
    "    See http://en.wikipedia.org/wiki/Arpabet or https://www.nltk.org/book/ch02.html, chapter 4.2 A Pronouncing Dictionary,\n",
    "    based on the nltk.corpus.cmudict CMU Pronouncing Dictionary for US English.\n",
    "    \"\"\"\n",
    "    if reverse:\n",
    "        word_pattern = word_pattern[::-1]\n",
    "        line_pattern = line_pattern[::-1]\n",
    "    for w, l in zip(list(word_pattern), list(line_pattern)):\n",
    "        if (l == '2') or (w == '2') or (w == l):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "published-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poetry_line(seed, pattern, reverse=False):\n",
    "    # look up list of following words\n",
    "    f_words = markov_backward[seed] if reverse else markov_forward[seed]\n",
    "    \n",
    "    # order the markov words in random order\n",
    "    for fw in random.sample(f_words, len(f_words)):\n",
    "        # get the pattern of the word\n",
    "        next_word_pattern = stress_pattern(fw)\n",
    "        if next_word_pattern and pattern_match(next_word_pattern, pattern, reverse):\n",
    "            remaining_pattern = pattern[:-len(next_word_pattern)] if reverse else pattern[len(next_word_pattern):]\n",
    "            # if no more pattern to consume, return the word we found\n",
    "            if remaining_pattern == '':\n",
    "                return [fw, ]\n",
    "            else:\n",
    "                remaining_phrase = poetry_line(fw, remaining_pattern, reverse)\n",
    "                if remaining_phrase:\n",
    "                    return remaining_phrase + [fw, ] if reverse else [fw, ] + remaining_phrase\n",
    "                \n",
    "    # we didn't find a chain that matches the pattern\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-denmark",
   "metadata": {},
   "source": [
    "# Generate words that rhyme\n",
    "\n",
    "- Go through each word, select the last vowel and any following consonants\n",
    "- Add to a rhyme dictionary\n",
    "\n",
    "Any words in the same rhyme class will also automatically have the same pattern!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "facial-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_rhyme(word):\n",
    "    # look up the word in the cmudict\n",
    "    if word in cmu_dict:\n",
    "        # get the first pronounciation of the word\n",
    "        cmu_word = cmu_dict[word][0]\n",
    "        # find the last vowel\n",
    "        rhyme = []\n",
    "        for phone in cmu_word[::-1]:\n",
    "            if phone[-1] in '012':\n",
    "                rhyme.append(phone)\n",
    "                break\n",
    "            else:\n",
    "                rhyme.append(phone)\n",
    "        return tuple(rhyme[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "vietnamese-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rhyme_dict(words):\n",
    "    rhyme_dict = defaultdict(set)\n",
    "    for w in words:\n",
    "        rhyme_dict[word_rhyme(w)].add(w)\n",
    "        \n",
    "    return rhyme_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-martin",
   "metadata": {},
   "source": [
    "# Generate multiple lines based on line patterns and lines rhyming with each other\n",
    "\n",
    "- Pick a start word based on:\n",
    "    - the pattern to match (e.g. pick a word '010' if line pattern ends in '010'\n",
    "    - the number of rhymes required (e.g. if lines 1 and 3 need to rhyme, pick a class of words that rhyme with each other\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "likely-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_block(rhyming_lines, patterns, words):\n",
    "    diff_rhymes = defaultdict(int)\n",
    "    for r in rhyming_lines:\n",
    "        diff_rhymes[r] += 1\n",
    "        \n",
    "    line_rhymes = defaultdict(list)\n",
    "    for r in diff_rhymes:\n",
    "        lines = [patterns[i] for i, line in enumerate(rhyming_lines) if line == r]\n",
    "        l_pat = lines[0]\n",
    "        # pick a word that matches the pattern end and that has the required number of rhymes\n",
    "        while True:\n",
    "            w = random.choice(words)\n",
    "            w_pat = stress_pattern(w)\n",
    "            rh = rhymes[word_rhyme(w)]\n",
    "            if w_pat and pattern_match(w_pat, l_pat, reverse=True) and len(rh) >= diff_rhymes[r]:\n",
    "                line_rhymes[r].append(w)\n",
    "                for _ in range(1, diff_rhymes[r]):\n",
    "                    while True:\n",
    "                        w_rhyme = random.choice(list(rh))\n",
    "                        if w_rhyme not in line_rhymes[r] and pattern_match(stress_pattern(w_rhyme), l_pat, reverse=True):\n",
    "                            line_rhymes[r].append(w_rhyme)\n",
    "                            break\n",
    "                break\n",
    "        \n",
    "    rhyme_block = []\n",
    "    rhyme_word_count = defaultdict(int)\n",
    "    for r, p in zip(rhyming_lines, patterns):\n",
    "        seed = line_rhymes[r][rhyme_word_count[r]]\n",
    "        rhyme_block.append(poetry_line(seed, p[:-len(seed)], reverse=True) + [seed, ])\n",
    "        rhyme_word_count[r] += 1\n",
    "                           \n",
    "    return rhyme_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "distinguished-correlation",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-90721cfb034d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpoem_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'0101010101'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-97-e4d775a48cc0>\u001b[0m in \u001b[0;36mpoem_block\u001b[1;34m(rhyming_lines, patterns, words)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrhyming_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline_rhymes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrhyme_word_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mrhyme_block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoetry_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mrhyme_word_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'list'"
     ]
    }
   ],
   "source": [
    "poem_block([0, 1, 0, 1], ['0101010101'] * 4, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-librarian",
   "metadata": {},
   "source": [
    "# Test the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "conscious-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = cleanup_text(sample_text)\n",
    "markov_forward, markov_backward = generate_markov(clean_text)\n",
    "rhymes = generate_rhyme_dict(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "primary-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['IH1', 'SH', 'M', 'IY0', 'L'], ['IH1', 'SH', 'M', 'EY0', 'L']]\n",
      "10\n",
      "[['W', 'EY1', 'L'], ['HH', 'W', 'EY1', 'L']]\n",
      "1\n",
      "[['SH', 'IH1', 'P']]\n",
      "1\n",
      "[['K', 'AA2', 'N', 'D', 'IH0', 'S', 'EH1', 'N', 'D', 'IH0', 'NG']]\n",
      "2010\n"
     ]
    }
   ],
   "source": [
    "test_words = ['ishmael', 'whale', 'ship', 'condescending']\n",
    "for tw in test_words:\n",
    "    print(cmu_dict[tw])\n",
    "    print(stress_pattern(tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "approximate-recycling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volume', 'whose', 'and', 'speculations', 'bandied']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random.seed(2021)\n",
    "seed = random.choice(clean_text)\n",
    "poetry_line(seed, '1010101010', reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "impressive-penny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ale',\n",
       " 'assail',\n",
       " 'avail',\n",
       " 'bale',\n",
       " 'dale',\n",
       " 'detail',\n",
       " 'exhale',\n",
       " 'fail',\n",
       " 'frail',\n",
       " 'gale',\n",
       " 'hail',\n",
       " 'inhale',\n",
       " 'jail',\n",
       " 'mail',\n",
       " 'male',\n",
       " 'nail',\n",
       " 'pail',\n",
       " 'pale',\n",
       " 'prevail',\n",
       " 'rail',\n",
       " 'sail',\n",
       " 'scale',\n",
       " 'tail',\n",
       " 'tale',\n",
       " 'trail',\n",
       " 'vale',\n",
       " 'veil',\n",
       " 'wail',\n",
       " 'whale',\n",
       " 'yale'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhymes[word_rhyme('whale')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
